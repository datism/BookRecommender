{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "from typing import Dict, Text\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_recommenders as tfrs\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"retrival\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataPath = \"hdfs://localhost:9000/user/nhom7/book/data/\"\n",
    "ratingsFilePath = dataPath + \"BX-Book-Ratings.csv\"\n",
    "rating_df = spark.read.options(inferSchema=\"true\", header=\"true\", delimiter=';').csv(ratingsFilePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\dd\\.virtualenvs\\tf_rec-5MMI-Cvb\\lib\\site-packages\\tensorflow\\python\\autograph\\pyct\\static_analysis\\liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
      "Instructions for updating:\n",
      "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
     ]
    }
   ],
   "source": [
    "ratings = tf.data.Dataset.from_tensor_slices(dict(rating_df.toPandas()))\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"isbn\": x[\"ISBN\"],\n",
    "    \"user_id\": x[\"User-ID\"],\n",
    "    \"user_rating\": x[\"Book-Rating\"]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "book_isbns = ratings.batch(1_000_000).map(lambda x: x[\"isbn\"])\n",
    "user_ids = ratings.batch(1_000_000).map(lambda x: x[\"user_id\"])\n",
    "\n",
    "unique_book_isbns = np.unique(np.concatenate(list(book_isbns)))\n",
    "unique_user_ids = np.unique(np.concatenate(list(user_ids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RankingModel(tf.keras.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    embedding_dimension = 32\n",
    "\n",
    "    # Compute embeddings for users.\n",
    "    self.user_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.IntegerLookup(\n",
    "        vocabulary=unique_user_ids, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_user_ids) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute embeddings for books.\n",
    "    self.book_embeddings = tf.keras.Sequential([\n",
    "      tf.keras.layers.StringLookup(\n",
    "        vocabulary=unique_book_isbns, mask_token=None),\n",
    "      tf.keras.layers.Embedding(len(unique_book_isbns) + 1, embedding_dimension)\n",
    "    ])\n",
    "\n",
    "    # Compute predictions.\n",
    "    self.ratings = tf.keras.Sequential([\n",
    "      # Learn multiple dense layers.\n",
    "      tf.keras.layers.Dense(256, activation=\"relu\"),\n",
    "      tf.keras.layers.Dense(64, activation=\"relu\"),\n",
    "      # Make rating predictions in the final layer.\n",
    "      tf.keras.layers.Dense(1)\n",
    "    ])\n",
    "\n",
    "  def call(self, inputs):\n",
    "\n",
    "    user_id, book_isbn = inputs\n",
    "\n",
    "    user_embedding = self.user_embeddings(user_id)\n",
    "    book_embedding = self.book_embeddings(book_isbn)\n",
    "\n",
    "    return self.ratings(tf.concat([user_embedding, book_embedding], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BookRecModel(tfrs.models.Model):\n",
    "\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.ranking_model: tf.keras.Model = RankingModel()\n",
    "    self.task: tf.keras.layers.Layer = tfrs.tasks.Ranking(\n",
    "      loss = tf.keras.losses.MeanSquaredError(),\n",
    "      metrics=[tf.keras.metrics.RootMeanSquaredError()]\n",
    "    )\n",
    "\n",
    "  def call(self, features: Dict[str, tf.Tensor]) -> tf.Tensor:\n",
    "    return self.ranking_model(\n",
    "        (features[\"user_id\"], features[\"isbn\"]))\n",
    "\n",
    "  def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "    labels = features.pop(\"user_rating\")\n",
    "\n",
    "    rating_predictions = self(features)\n",
    "\n",
    "    # The task computes the loss and the metrics.\n",
    "    return self.task(labels=labels, predictions=rating_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BookRecModel()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(learning_rate=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cached_train = train.shuffle(100_000).batch(8192).cache()\n",
    "cached_test = test.batch(4096).cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "10/10 [==============================] - 9s 86ms/step - root_mean_squared_error: 4.1452 - loss: 16.9002 - regularization_loss: 0.0000e+00 - total_loss: 16.9002\n",
      "Epoch 2/3\n",
      "10/10 [==============================] - 1s 61ms/step - root_mean_squared_error: 3.8024 - loss: 14.3865 - regularization_loss: 0.0000e+00 - total_loss: 14.3865\n",
      "Epoch 3/3\n",
      "10/10 [==============================] - 1s 58ms/step - root_mean_squared_error: 3.6903 - loss: 13.5377 - regularization_loss: 0.0000e+00 - total_loss: 13.5377\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x23f02ba1900>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(cached_train, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 3s 87ms/step - root_mean_squared_error: 3.6180 - loss: 13.1307 - regularization_loss: 0.0000e+00 - total_loss: 13.1307\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'root_mean_squared_error': 3.6180074214935303,\n",
       " 'loss': 13.308781623840332,\n",
       " 'regularization_loss': 0,\n",
       " 'total_loss': 13.308781623840332}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(cached_test, return_dict=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ratings:\n",
      "0380841940: [[3.9059367]]\n",
      "0553114271: [[3.9003487]]\n",
      "0812510488: [[3.8594904]]\n",
      "0345404793: [[3.8563402]]\n",
      "0451129040: [[3.8072798]]\n"
     ]
    }
   ],
   "source": [
    "test_ratings = {}\n",
    "test_book_isbns = [\"0345404793\",\n",
    "                \"0380841940\",\n",
    "                \"0451129040\",\n",
    "                \"0812510488\",\n",
    "                \"0553114271\",]\n",
    "for book_isbn in test_book_isbns:\n",
    "  test_ratings[book_isbn] = model({\n",
    "      \"user_id\": np.array([12]),\n",
    "      \"isbn\": np.array([book_isbn])\n",
    "  })\n",
    "\n",
    "print(\"Ratings:\")\n",
    "for title, score in sorted(test_ratings.items(), key=lambda x: x[1], reverse=True):\n",
    "  print(f\"{title}: {score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as ranking_layer_call_fn, ranking_layer_call_and_return_conditional_losses, _update_step_xla while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/ranking_model/1/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/ranking_model/1/assets\n"
     ]
    }
   ],
   "source": [
    "path = (\"./model/ranking_model/1/\")\n",
    "tf.saved_model.save(model, path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf_rec-5MMI-Cvb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "77e106df7f450c66566a7610a3718f206c95a104637392e72bdeaab378155cd7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
